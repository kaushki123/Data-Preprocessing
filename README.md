# Mastering Data-Preprocessing
Mastering Data Preprocessing â€“ Titanic Dataset This notebook demonstrates essential data preprocessing steps on the Titanic dataset using Python, Pandas, and scikit-learn. It includes handling missing values, encoding categorical variables, feature scaling, and train-test splitting â€” preparing the data for machine learning models.


ğŸš¢ **Mastering Data Preprocessing â€“ Titanic - Machine Learning from Disaster Dataset**

This project demonstrates the essential steps of data preprocessing using the Titanic dataset. It is designed for beginners and intermediate learners who want to understand how to clean and prepare real-world data for machine learning models.

ğŸ“Œ Overview :-

The notebook walks through the following preprocessing steps using Python, Pandas, and scikit-learn:

âœ… Loading the Titanic dataset (CSV)

ğŸ§¼ Handling missing values (Age, Embarked, Cabin)

ğŸ” Checking for and confirming no duplicate entries

ğŸ”¡ Encoding categorical variables (Sex and Embarked)

ğŸ“ Feature scaling with StandardScaler (Age and Fare)

ğŸ“Š Feature selection (8 key columns)

ğŸ”€ Train-test split using train_test_split (80% / 20%)


ğŸ› ï¸ Tools & Libraries Used :-

* Python ğŸ

* Pandas ğŸ“Š

* Scikit-learn (sklearn) ğŸ§ 


ğŸ“Œ How to Use :-

-Clone the repository

-Open the Google Colab notebook

-Ensure the Titanic CSV is available in our working directory

-Run the cells to follow each preprocessing step


âœ… Preprocessing Outcome :-

* Cleaned, scaled, and encoded data

* Ready-to-use feature set for machine learning models



